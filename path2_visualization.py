"""
Path 2 Visualization & Testing Tools
å¯è§†åŒ–è¿åŠ¨åºåˆ—å’ŒLSTMé¢„æµ‹ç»“æœ
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.animation import FuncAnimation
import torch
from pathlib import Path


def visualize_motion_sequence(json_file: str, camera_id: int = 0, save_gif: bool = False):
    """
    å¯è§†åŒ–è¿åŠ¨åºåˆ—
    
    Args:
        json_file: è¿åŠ¨åºåˆ—JSONæ–‡ä»¶è·¯å¾„
        camera_id: è¦å¯è§†åŒ–çš„ç›¸æœºID
        save_gif: æ˜¯å¦ä¿å­˜ä¸ºGIFåŠ¨ç”»
    """
    # åŠ è½½æ•°æ®
    with open(json_file, 'r') as f:
        data = json.load(f)
    
    # è¿‡æ»¤æŒ‡å®šç›¸æœºçš„æ•°æ®
    camera_data = [d for d in data if d['camera_id'] == camera_id]
    
    if not camera_data:
        print(f"âš ï¸  No data found for camera {camera_id}")
        return
    
    print(f"ğŸ“Š Visualizing {len(camera_data)} frames from camera {camera_id}")
    
    # åˆ›å»ºå›¾å½¢
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # å·¦å›¾: 2Dè½¨è¿¹
    ax1.set_title(f'Camera {camera_id} - 2D Trajectories')
    ax1.set_xlabel('X (pixels)')
    ax1.set_ylabel('Y (pixels)')
    ax1.set_xlim(0, 640)
    ax1.set_ylim(480, 0)  # å›¾åƒåæ ‡ç³»Yè½´å‘ä¸‹
    ax1.grid(True, alpha=0.3)
    
    # å³å›¾: 3Dè½¨è¿¹
    ax2 = fig.add_subplot(122, projection='3d')
    ax2.set_title('World Space - 3D Trajectories')
    ax2.set_xlabel('X (m)')
    ax2.set_ylabel('Y (m)')
    ax2.set_zlabel('Z (m)')
    
    # æ”¶é›†æ‰€æœ‰ç‰©ä½“çš„è½¨è¿¹
    trajectories_2d = {}
    trajectories_3d = {}
    
    for frame_data in camera_data:
        for obj in frame_data['objects']:
            obj_id = obj['id']
            
            if obj_id not in trajectories_2d:
                trajectories_2d[obj_id] = {'x': [], 'y': []}
                trajectories_3d[obj_id] = {'x': [], 'y': [], 'z': []}
            
            # 2D bboxä¸­å¿ƒ
            bbox = obj['bbox']
            cx = (bbox[0] + bbox[2]) / 2
            cy = (bbox[1] + bbox[3]) / 2
            trajectories_2d[obj_id]['x'].append(cx)
            trajectories_2d[obj_id]['y'].append(cy)
            
            # 3Dä½ç½®
            pos_3d = obj['pos_3d']
            trajectories_3d[obj_id]['x'].append(pos_3d[0])
            trajectories_3d[obj_id]['y'].append(pos_3d[1])
            trajectories_3d[obj_id]['z'].append(pos_3d[2])
    
    # ç»˜åˆ¶è½¨è¿¹
    colors = plt.cm.rainbow(np.linspace(0, 1, len(trajectories_2d)))
    
    for (obj_id, traj_2d), (_, traj_3d), color in zip(
        trajectories_2d.items(), 
        trajectories_3d.items(), 
        colors
    ):
        # 2Dè½¨è¿¹
        ax1.plot(traj_2d['x'], traj_2d['y'], 
                label=f'Object {obj_id}', 
                color=color, 
                linewidth=2, 
                alpha=0.7)
        ax1.scatter(traj_2d['x'][0], traj_2d['y'][0], 
                   color=color, 
                   s=100, 
                   marker='o', 
                   label=f'Start {obj_id}')
        ax1.scatter(traj_2d['x'][-1], traj_2d['y'][-1], 
                   color=color, 
                   s=100, 
                   marker='X', 
                   label=f'End {obj_id}')
        
        # 3Dè½¨è¿¹
        ax2.plot(traj_3d['x'], traj_3d['y'], traj_3d['z'], 
                color=color, 
                linewidth=2, 
                alpha=0.7)
        ax2.scatter(traj_3d['x'][0], traj_3d['y'][0], traj_3d['z'][0], 
                   color=color, 
                   s=100, 
                   marker='o')
        ax2.scatter(traj_3d['x'][-1], traj_3d['y'][-1], traj_3d['z'][-1], 
                   color=color, 
                   s=100, 
                   marker='X')
    
    ax1.legend(loc='upper right', fontsize=8)
    
    plt.tight_layout()
    
    if save_gif:
        output_path = Path(json_file).parent / f"camera_{camera_id}_trajectories.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"âœ… Saved visualization to {output_path}")
    
    plt.show()


def analyze_lstm_predictions(
    model_path: str,
    json_file: str,
    num_samples: int = 5
):
    """
    åˆ†æLSTMé¢„æµ‹ç»“æœ
    
    Args:
        model_path: è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„
        json_file: æµ‹è¯•æ•°æ®JSONæ–‡ä»¶
        num_samples: å¯è§†åŒ–æ ·æœ¬æ•°é‡
    """
    from path2_stage1_2_implementation import LSTMTracker, TrackingDataset
    
    # åŠ è½½æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = LSTMTracker(
        input_size=4,
        hidden_size=128,
        num_layers=2,
        output_size=4
    )
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    print(f"âœ… Loaded model from {model_path}")
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = TrackingDataset(
        json_file=json_file,
        sequence_length=10,
        prediction_horizon=5
    )
    
    print(f"ğŸ“Š Dataset size: {len(dataset)} samples")
    
    if len(dataset) == 0:
        print("âš ï¸  No samples in dataset")
        return
    
    # éšæœºé€‰æ‹©æ ·æœ¬
    indices = np.random.choice(len(dataset), min(num_samples, len(dataset)), replace=False)
    
    fig, axes = plt.subplots(num_samples, 1, figsize=(12, 4*num_samples))
    if num_samples == 1:
        axes = [axes]
    
    with torch.no_grad():
        for i, idx in enumerate(indices):
            input_seq, target_seq = dataset[idx]
            
            # é¢„æµ‹
            input_tensor = input_seq.unsqueeze(0).to(device)
            predictions = model.predict_sequence(input_tensor, steps=target_seq.size(0))
            predictions = predictions.squeeze(0).cpu().numpy()
            
            # è½¬æ¢ä¸ºnumpy
            input_np = input_seq.numpy()
            target_np = target_seq.numpy()
            
            # å¯è§†åŒ–
            ax = axes[i]
            
            # è¾“å…¥åºåˆ—
            time_input = np.arange(len(input_np))
            ax.plot(time_input, input_np[:, 0], 'b-', label='Input X1', alpha=0.7)
            ax.plot(time_input, input_np[:, 2], 'g-', label='Input X2', alpha=0.7)
            
            # ç›®æ ‡åºåˆ—
            time_target = np.arange(len(input_np), len(input_np) + len(target_np))
            ax.plot(time_target, target_np[:, 0], 'b--', label='Target X1', linewidth=2)
            ax.plot(time_target, target_np[:, 2], 'g--', label='Target X2', linewidth=2)
            
            # é¢„æµ‹åºåˆ—
            ax.plot(time_target, predictions[:, 0], 'r-', label='Pred X1', linewidth=2)
            ax.plot(time_target, predictions[:, 2], 'orange', label='Pred X2', linewidth=2)
            
            # è®¡ç®—è¯¯å·®
            mse = np.mean((predictions - target_np) ** 2)
            
            ax.set_title(f'Sample {i+1} - MSE: {mse:.4f}')
            ax.set_xlabel('Time Step')
            ax.set_ylabel('Pixel Coordinate')
            ax.legend(loc='upper right')
            ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    output_path = Path(model_path).parent / "prediction_analysis.png"
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"âœ… Saved analysis to {output_path}")
    
    plt.show()


def compute_tracking_metrics(
    model_path: str,
    json_file: str
):
    """
    è®¡ç®—è·Ÿè¸ªæ€§èƒ½æŒ‡æ ‡
    
    Args:
        model_path: æ¨¡å‹è·¯å¾„
        json_file: æµ‹è¯•æ•°æ®è·¯å¾„
    """
    from path2_stage1_2_implementation import LSTMTracker, TrackingDataset
    
    # åŠ è½½æ¨¡å‹
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = LSTMTracker(
        input_size=4,
        hidden_size=128,
        num_layers=2,
        output_size=4
    )
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval()
    
    # åˆ›å»ºæ•°æ®é›†
    dataset = TrackingDataset(
        json_file=json_file,
        sequence_length=10,
        prediction_horizon=5
    )
    
    if len(dataset) == 0:
        print("âš ï¸  No samples for evaluation")
        return
    
    print("ğŸ” Computing tracking metrics...")
    
    # è®¡ç®—æŒ‡æ ‡
    all_errors = []
    all_ious = []
    
    with torch.no_grad():
        for i in range(len(dataset)):
            input_seq, target_seq = dataset[i]
            
            # é¢„æµ‹
            input_tensor = input_seq.unsqueeze(0).to(device)
            predictions = model.predict_sequence(input_tensor, steps=target_seq.size(0))
            predictions = predictions.squeeze(0).cpu().numpy()
            target_np = target_seq.numpy()
            
            # L2è¯¯å·®
            error = np.sqrt(np.sum((predictions - target_np) ** 2, axis=1))
            all_errors.extend(error)
            
            # IoU (ç®€åŒ–è®¡ç®—)
            for pred_box, target_box in zip(predictions, target_np):
                iou = compute_iou(pred_box, target_box)
                all_ious.append(iou)
    
    # æ‰“å°ç»Ÿè®¡
    print("\n" + "=" * 50)
    print("ğŸ“Š Tracking Performance Metrics")
    print("=" * 50)
    print(f"Total Predictions: {len(all_errors)}")
    print(f"\nL2 Error (pixels):")
    print(f"  Mean:   {np.mean(all_errors):.2f}")
    print(f"  Median: {np.median(all_errors):.2f}")
    print(f"  Std:    {np.std(all_errors):.2f}")
    print(f"  Min:    {np.min(all_errors):.2f}")
    print(f"  Max:    {np.max(all_errors):.2f}")
    print(f"\nIoU:")
    print(f"  Mean:   {np.mean(all_ious):.3f}")
    print(f"  Median: {np.median(all_ious):.3f}")
    print(f"  >0.5:   {np.sum(np.array(all_ious) > 0.5) / len(all_ious) * 100:.1f}%")
    print("=" * 50)


def compute_iou(box1, box2):
    """è®¡ç®—IoU"""
    x1_min, y1_min, x1_max, y1_max = box1
    x2_min, y2_min, x2_max, y2_max = box2
    
    # è®¡ç®—äº¤é›†
    inter_x_min = max(x1_min, x2_min)
    inter_y_min = max(y1_min, y2_min)
    inter_x_max = min(x1_max, x2_max)
    inter_y_max = min(y1_max, y2_max)
    
    if inter_x_max < inter_x_min or inter_y_max < inter_y_min:
        return 0.0
    
    inter_area = (inter_x_max - inter_x_min) * (inter_y_max - inter_y_min)
    
    # è®¡ç®—å¹¶é›†
    box1_area = (x1_max - x1_min) * (y1_max - y1_min)
    box2_area = (x2_max - x2_min) * (y2_max - y2_min)
    union_area = box1_area + box2_area - inter_area
    
    return inter_area / union_area if union_area > 0 else 0.0


def main():
    """æ¼”ç¤ºæ‰€æœ‰å¯è§†åŒ–åŠŸèƒ½"""
    print("ğŸ¨ Path 2 Visualization Tools\n")
    
    json_file = "./path2_output/stage1/motion_sequence.json"
    model_file = "./path2_output/stage2/best_lstm_tracker.pth"
    
    if not Path(json_file).exists():
        print(f"âš ï¸  Data file not found: {json_file}")
        print("   Please run path2_stage1_2_implementation.py first")
        return
    
    # 1. å¯è§†åŒ–è¿åŠ¨åºåˆ—
    print("1ï¸âƒ£  Visualizing motion sequences...")
    visualize_motion_sequence(json_file, camera_id=0, save_gif=True)
    
    if not Path(model_file).exists():
        print(f"\nâš ï¸  Model file not found: {model_file}")
        print("   Skipping LSTM analysis")
        return
    
    # 2. åˆ†æLSTMé¢„æµ‹
    print("\n2ï¸âƒ£  Analyzing LSTM predictions...")
    analyze_lstm_predictions(model_file, json_file, num_samples=3)
    
    # 3. è®¡ç®—æ€§èƒ½æŒ‡æ ‡
    print("\n3ï¸âƒ£  Computing tracking metrics...")
    compute_tracking_metrics(model_file, json_file)
    
    print("\nâœ… All visualizations completed!")


if __name__ == "__main__":
    main()
