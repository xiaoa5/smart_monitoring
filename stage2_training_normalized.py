"""
Path 2 Stage 2 - LSTM Training with Data Normalization
ä¿®å¤ç‰ˆæœ¬: æ·»åŠ æ•°æ®å½’ä¸€åŒ–,æå‡LSTMé¢„æµ‹æ€§èƒ½

Key Improvements:
1. âœ… å°†bboxåƒç´ åæ ‡å½’ä¸€åŒ–åˆ°[0,1]
2. âœ… è®­ç»ƒæ—¶ä½¿ç”¨å½’ä¸€åŒ–æ•°æ®
3. âœ… é¢„æµ‹æ—¶åå½’ä¸€åŒ–å›åƒç´ åæ ‡
4. âœ… æŒ‰è¿åŠ¨ç±»å‹åˆ†åˆ«ç»Ÿè®¡æ€§èƒ½

Author: AI Assistant
Date: 2025-11-14 (Normalized Version)
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import os
from pathlib import Path
from typing import Optional


# ============================================================================
# Stage 2: LSTM Tracker with Normalization
# ============================================================================

class TrackingDatasetNormalized(Dataset):
    """
    LSTMè·Ÿè¸ªæ•°æ®é›† - å¸¦å½’ä¸€åŒ–
    
    å…³é”®æ”¹è¿›: å°†bbox_pixelså½’ä¸€åŒ–åˆ°[0,1]èŒƒå›´
    è¾“å…¥: [x1/W, y1/H, x2/W, y2/H]
    """
    
    def __init__(
        self,
        json_file: str,
        sequence_length: int = 10,
        prediction_horizon: int = 5,
        image_size: tuple = (640, 480),
        normalize: bool = True
    ):
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.image_width, self.image_height = image_size
        self.normalize = normalize
        
        # å½’ä¸€åŒ–å› å­
        self.norm_factors = np.array([
            self.image_width,   # x1
            self.image_height,  # y1
            self.image_width,   # x2
            self.image_height   # y2
        ], dtype=np.float32)
        
        # åŠ è½½æ•°æ®
        with open(json_file, 'r') as f:
            self.data = json.load(f)
        
        # æŒ‰ç›¸æœºå’Œç‰©ä½“IDç»„ç»‡è½¨è¿¹
        self.trajectories = self._organize_trajectories()
        
        # ç”Ÿæˆè®­ç»ƒæ ·æœ¬
        self.samples = self._generate_samples()
        
        print(f"ğŸ“Š Dataset Statistics:")
        print(f"   Total samples: {len(self.samples)}")
        print(f"   Image size: {self.image_width} Ã— {self.image_height}")
        if self.normalize:
            print(f"   Normalization: âœ… ON (bbox â†’ [0,1])")
        else:
            print(f"   Normalization: âŒ OFF (raw pixels)")
    
    def _organize_trajectories(self):
        """ç»„ç»‡è½¨è¿¹æ•°æ®"""
        trajectories = {}
        
        for frame_data in self.data:
            cam_id = frame_data['camera_id']
            
            if cam_id not in trajectories:
                trajectories[cam_id] = {}
            
            for obj in frame_data['objects']:
                obj_id = obj['id']
                
                if obj_id not in trajectories[cam_id]:
                    trajectories[cam_id][obj_id] = []
                
                # ä½¿ç”¨åƒç´ åæ ‡bbox
                if 'bbox_pixels' in obj:
                    bbox = np.array(obj['bbox_pixels'], dtype=np.float32)
                else:
                    # fallback: ä»YOLOæ ¼å¼è½¬æ¢
                    cx, cy, w, h = obj['bbox']
                    x1 = (cx - w/2) * self.image_width
                    y1 = (cy - h/2) * self.image_height
                    x2 = (cx + w/2) * self.image_width
                    y2 = (cy + h/2) * self.image_height
                    bbox = np.array([x1, y1, x2, y2], dtype=np.float32)
                
                # å½’ä¸€åŒ–
                if self.normalize:
                    bbox = bbox / self.norm_factors
                
                trajectories[cam_id][obj_id].append({
                    'frame': frame_data['frame'],
                    'bbox': bbox,
                    'motion_type': obj.get('motion_type', 'unknown')
                })
        
        return trajectories
    
    def _generate_samples(self):
        """ç”Ÿæˆè®­ç»ƒæ ·æœ¬"""
        samples = []
        
        for cam_id, objects in self.trajectories.items():
            for obj_id, trajectory in objects.items():
                if len(trajectory) < self.sequence_length + self.prediction_horizon:
                    continue
                
                motion_type = trajectory[0]['motion_type']
                
                # æ»‘åŠ¨çª—å£
                for i in range(len(trajectory) - self.sequence_length - self.prediction_horizon + 1):
                    input_seq = trajectory[i:i + self.sequence_length]
                    target_seq = trajectory[i + self.sequence_length:
                                          i + self.sequence_length + self.prediction_horizon]
                    
                    input_bboxes = np.array([t['bbox'] for t in input_seq])
                    target_bboxes = np.array([t['bbox'] for t in target_seq])
                    
                    samples.append({
                        'input': input_bboxes,
                        'target': target_bboxes,
                        'obj_id': obj_id,
                        'cam_id': cam_id,
                        'motion_type': motion_type
                    })
        
        return samples
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        sample = self.samples[idx]
        
        input_seq = torch.FloatTensor(sample['input'])
        target_seq = torch.FloatTensor(sample['target'])
        
        return input_seq, target_seq
    
    def denormalize_bbox(self, bbox_normalized):
        """
        å°†å½’ä¸€åŒ–çš„bboxè½¬æ¢å›åƒç´ åæ ‡
        
        Args:
            bbox_normalized: [x1_norm, y1_norm, x2_norm, y2_norm] in [0,1]
        Returns:
            bbox_pixels: [x1, y1, x2, y2] in pixels
        """
        if isinstance(bbox_normalized, torch.Tensor):
            bbox_normalized = bbox_normalized.cpu().numpy()
        
        bbox_pixels = bbox_normalized * self.norm_factors
        return bbox_pixels


class LSTMTracker(nn.Module):
    """
    LSTMå¤šç›®æ ‡è·Ÿè¸ªå™¨
    
    è¾“å…¥: (batch, seq_len=10, input_size=4) - å½’ä¸€åŒ–çš„bbox
    è¾“å‡º: (batch, output_size=4) - å½’ä¸€åŒ–çš„bboxé¢„æµ‹
    """
    
    def __init__(
        self,
        input_size: int = 4,
        hidden_size: int = 128,
        num_layers: int = 2,
        output_size: int = 4,
        dropout: float = 0.2
    ):
        super(LSTMTracker, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTMå±‚
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=dropout if num_layers > 1 else 0
        )
        
        # å…¨è¿æ¥å±‚
        self.fc = nn.Sequential(
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size // 2, output_size)
        )
    
    def forward(self, x, hidden=None):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: (batch, seq_len, input_size)
            hidden: (h0, c0) or None
        Returns:
            output: (batch, output_size)
            hidden: (h, c)
        """
        lstm_out, hidden = self.lstm(x, hidden)
        last_output = lstm_out[:, -1, :]
        prediction = self.fc(last_output)
        
        return prediction, hidden
    
    def predict_sequence(self, x, steps: int = 5):
        """
        è‡ªå›å½’é¢„æµ‹å¤šæ­¥
        
        Args:
            x: (batch, seq_len, input_size)
            steps: é¢„æµ‹æ­¥æ•°
        Returns:
            predictions: (batch, steps, output_size)
        """
        predictions = []
        current_seq = x.clone()
        hidden = None
        
        for _ in range(steps):
            pred, hidden = self.forward(current_seq, hidden)
            predictions.append(pred)
            current_seq = torch.cat([current_seq[:, 1:, :], pred.unsqueeze(1)], dim=1)
        
        return torch.stack(predictions, dim=1)


class LSTMTrackerTrainer:
    """LSTMè·Ÿè¸ªå™¨è®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model: LSTMTracker,
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        learning_rate: float = 0.001
    ):
        self.model = model.to(device)
        self.device = device
        
        self.criterion = nn.MSELoss()
        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
        
        self.train_losses = []
        self.val_losses = []
    
    def train_epoch(self, train_loader: DataLoader) -> float:
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        
        for inputs, targets in train_loader:
            inputs = inputs.to(self.device)
            targets = targets.to(self.device)
            
            self.optimizer.zero_grad()
            
            # é¢„æµ‹æ‰€æœ‰æœªæ¥æ­¥
            predictions = self.model.predict_sequence(inputs, steps=targets.size(1))
            
            # è®¡ç®—æŸå¤±
            loss = self.criterion(predictions, targets)
            
            # åå‘ä¼ æ’­
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / len(train_loader)
        return avg_loss
    
    def validate(self, val_loader: DataLoader) -> float:
        """éªŒè¯"""
        self.model.eval()
        total_loss = 0
        
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs = inputs.to(self.device)
                targets = targets.to(self.device)
                
                predictions = self.model.predict_sequence(inputs, steps=targets.size(1))
                loss = self.criterion(predictions, targets)
                
                total_loss += loss.item()
        
        avg_loss = total_loss / len(val_loader)
        return avg_loss
    
    def train(
        self,
        train_loader: DataLoader,
        val_loader: DataLoader,
        num_epochs: int = 50,
        save_path: Optional[str] = None
    ):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        best_val_loss = float('inf')
        patience = 10
        patience_counter = 0
        
        print(f"\nğŸš€ Starting training...")
        print(f"   Device: {self.device}")
        print(f"   Epochs: {num_epochs}")
        print(f"   Batch size: {train_loader.batch_size}")
        print(f"   Learning rate: {self.optimizer.param_groups[0]['lr']}")
        print()
        
        for epoch in range(num_epochs):
            train_loss = self.train_epoch(train_loader)
            val_loss = self.validate(val_loader)
            
            self.train_losses.append(train_loss)
            self.val_losses.append(val_loss)
            
            # æ‰“å°è¿›åº¦
            print(f"Epoch {epoch+1:3d}/{num_epochs} - "
                  f"Train Loss: {train_loss:8.4f}, Val Loss: {val_loss:8.4f}", end='')
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                if save_path:
                    torch.save(self.model.state_dict(), save_path)
                    print(f"  âœ… Saved (best: {val_loss:.4f})")
                else:
                    print(f"  â­ New best!")
            else:
                patience_counter += 1
                print()
            
            # Early stopping
            if patience_counter >= patience:
                print(f"\nâš ï¸  Early stopping at epoch {epoch+1} (no improvement for {patience} epochs)")
                break
        
        print(f"\nğŸ‰ Training completed!")
        print(f"   Best val loss: {best_val_loss:.4f}")
        print(f"   Final train loss: {train_loss:.4f}")


# ============================================================================
# Demo Functions
# ============================================================================

def train_lstm_with_normalization(
    json_file: str,
    output_dir: str = "./path2_output_corrected/stage2",
    num_epochs: int = 50,
    batch_size: int = 16,
    learning_rate: float = 0.001
):
    """
    ä½¿ç”¨å½’ä¸€åŒ–æ•°æ®è®­ç»ƒLSTM
    """
    print("=" * 80)
    print("Stage 2: LSTM Training with Normalization")
    print("=" * 80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºæ•°æ®é›† (å¸¦å½’ä¸€åŒ–!)
    print("\nğŸ“Š Creating normalized dataset...")
    dataset = TrackingDatasetNormalized(
        json_file=json_file,
        sequence_length=10,
        prediction_horizon=5,
        image_size=(640, 480),
        normalize=True  # â† å…³é”®!
    )
    
    if len(dataset) == 0:
        print("âš ï¸  No training samples generated.")
        print("   Try generating longer sequences (duration > 20s)")
        return
    
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    
    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size]
    )
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    
    print(f"\nğŸ“ˆ Data split:")
    print(f"   Train: {train_size} samples")
    print(f"   Val:   {val_size} samples")
    
    # åˆ›å»ºæ¨¡å‹
    print("\nğŸ§  Creating LSTM model...")
    model = LSTMTracker(
        input_size=4,
        hidden_size=128,
        num_layers=2,
        output_size=4,
        dropout=0.2
    )
    
    num_params = sum(p.numel() for p in model.parameters())
    print(f"   Parameters: {num_params:,}")
    
    # è®­ç»ƒ
    trainer = LSTMTrackerTrainer(
        model=model,
        device='cuda' if torch.cuda.is_available() else 'cpu',
        learning_rate=learning_rate
    )
    
    save_path = f"{output_dir}/best_lstm_tracker_normalized.pth"
    
    trainer.train(
        train_loader=train_loader,
        val_loader=val_loader,
        num_epochs=num_epochs,
        save_path=save_path
    )
    
    print(f"\nâœ… Model saved to: {save_path}")
    print(f"\nğŸ’¡ Expected improvement:")
    print(f"   With normalization: Loss should be < 0.01 (in [0,1] space)")
    print(f"   Which equals: ~25 pixels MAE in image space")
    
    return save_path


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    print("\n" + "=" * 80)
    print("ğŸš€ Path 2 Stage 2 - LSTM Training with Normalization")
    print("=" * 80)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    json_file = "./path2_output_corrected/stage1/motion_sequence.json"
    
    if not Path(json_file).exists():
        print(f"\nâš ï¸  Data file not found: {json_file}")
        print("   Please run path2_CORRECTED_v2.py first to generate data.")
        sys.exit(1)
    
    # è®­ç»ƒ
    model_path = train_lstm_with_normalization(
        json_file=json_file,
        num_epochs=50,
        batch_size=16,
        learning_rate=0.001
    )
    
    print("\n" + "=" * 80)
    print("âœ… Training completed!")
    print("=" * 80)
    print(f"\nğŸ“ Output files:")
    print(f"   Model: {model_path}")
    print(f"\nğŸ¨ Next steps:")
    print(f"   1. python enhanced_visualization.py  # å¯è§†åŒ–å¯¹æ¯”")
    print(f"   2. Check prediction quality")
    print(f"   3. Compare with non-normalized version")


if __name__ == "__main__":
    main()
