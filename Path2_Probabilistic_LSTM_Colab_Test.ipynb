{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path2 æ¦‚ç‡LSTM + çº¦æŸè·Ÿè¸ªç³»ç»Ÿ - Colabæµ‹è¯•\n",
    "\n",
    "## æµ‹è¯•é˜¶æ®µ\n",
    "- **é˜¶æ®µA**: åŸºç¡€æ•°æ®ç”Ÿæˆ (Stage 1)\n",
    "- **é˜¶æ®µB**: æ¦‚ç‡LSTM (è¾“å‡ºé«˜æ–¯åˆ†å¸ƒ)\n",
    "- **é˜¶æ®µC**: çº¦æŸç³»ç»Ÿ (è´å¶æ–¯æ›´æ–°)\n",
    "- **é˜¶æ®µD**: ç«¯åˆ°ç«¯é›†æˆ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ å®‰è£…ä¾èµ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…éªŒè¯è¿‡çš„ä¾èµ–ç‰ˆæœ¬\n",
    "!pip install --upgrade pip setuptools wheel\n",
    "!pip install pybullet==3.2.7 numpy==2.1.1 torch opencv-python matplotlib tqdm pyyaml scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print('PyTorch version:', torch.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device:', torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ ä¸Šä¼ ä»£ç æ–‡ä»¶\n",
    "\n",
    "ä¸Šä¼ ä»¥ä¸‹æ–‡ä»¶ï¼š\n",
    "- `path2_phase1_2_verified.py` (åŸºç¡€å®ç°)\n",
    "- `path2_probabilistic_lstm.py` (æ¦‚ç‡LSTM - é˜¶æ®µB)\n",
    "- `path2_constraints.py` (çº¦æŸç³»ç»Ÿ - é˜¶æ®µC)\n",
    "- `path2_integrated.py` (å®Œæ•´é›†æˆ - é˜¶æ®µD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# é˜¶æ®µ A: æµ‹è¯•åŸºç¡€å®ç°\n",
    "\n",
    "éªŒè¯æ•°æ®ç”Ÿæˆã€JSONæ ¼å¼ã€ç›‘ç£æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡ŒåŸºç¡€å®ç°\n",
    "!python path2_phase1_2_verified.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ£€æŸ¥ç”Ÿæˆçš„æ•°æ®\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "# è¯»å–JSON\n",
    "with open('./path2_output/stage1/motion_sequence.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(f\"Total frames: {len(data)}\")\n",
    "print(f\"\\nFirst frame sample:\")\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éªŒè¯é€Ÿåº¦æ˜¯å¦å˜åŒ–ï¼ˆæ£€æŸ¥ä¿®å¤ï¼‰\n",
    "import numpy as np\n",
    "\n",
    "# æå–æŸä¸ªç‰©ä½“åœ¨æŸä¸ªç›¸æœºçš„é€Ÿåº¦\n",
    "velocities = []\n",
    "for frame in data:\n",
    "    if frame['camera_id'] == 0:  # ç›¸æœº0\n",
    "        for obj in frame['objects']:\n",
    "            if obj['id'] == 1:  # ç‰©ä½“1ï¼ˆåœ†å‘¨è¿åŠ¨ï¼‰\n",
    "                velocities.append(obj['velocity'])\n",
    "\n",
    "velocities = np.array(velocities)\n",
    "\n",
    "# ç»˜åˆ¶é€Ÿåº¦å˜åŒ–\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(velocities[:, 0], label='vx')\n",
    "plt.plot(velocities[:, 1], label='vy')\n",
    "plt.legend()\n",
    "plt.title('Velocity over time (CIRCULAR motion)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Velocity (m/s)')\n",
    "\n",
    "# é€Ÿåº¦å¤§å°åº”è¯¥æ’å®šï¼ˆåœ†å‘¨è¿åŠ¨ï¼‰\n",
    "plt.subplot(1, 3, 2)\n",
    "speed = np.linalg.norm(velocities[:, :2], axis=1)\n",
    "plt.plot(speed)\n",
    "plt.title('Speed (should be constant)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Speed (m/s)')\n",
    "\n",
    "# é€Ÿåº¦æ–¹å‘å˜åŒ–\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(velocities[:, 0], velocities[:, 1], c=range(len(velocities)), cmap='viridis', s=5)\n",
    "plt.colorbar(label='Frame')\n",
    "plt.title('Velocity direction (should form circle)')\n",
    "plt.xlabel('vx')\n",
    "plt.ylabel('vy')\n",
    "plt.axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… é˜¶æ®µAéªŒè¯: é€Ÿåº¦æ­£ç¡®å˜åŒ–ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ç”Ÿæˆçš„å›¾åƒ\n",
    "import glob\n",
    "\n",
    "# æ˜¾ç¤º4ä¸ªç›¸æœºçš„åŒä¸€å¸§\n",
    "frame_idx = 100\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "for cam_id in range(4):\n",
    "    img_path = f'./path2_output/stage1/camera_{cam_id}/frame_{frame_idx:06d}.jpg'\n",
    "    img = Image.open(img_path)\n",
    "    \n",
    "    ax = axes[cam_id // 2, cam_id % 2]\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f'Camera {cam_id} - Frame {frame_idx}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… é˜¶æ®µAéªŒæ”¶æ ‡å‡†\n",
    "\n",
    "- [ ] JSONæ–‡ä»¶æ­£ç¡®ç”Ÿæˆ\n",
    "- [ ] åŒ…å« pos_3d, velocity, orientation, angular_velocity\n",
    "- [ ] é€Ÿåº¦éšæ—¶é—´å˜åŒ–ï¼ˆåœ†å‘¨è¿åŠ¨åº”è¯¥å½¢æˆåœ†ï¼‰\n",
    "- [ ] 4ä¸ªç›¸æœºå›¾åƒæ­£ç¡®ç”Ÿæˆ\n",
    "- [ ] Bboxåœ¨åˆç†èŒƒå›´å†…\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é˜¶æ®µ B: æ¦‚ç‡LSTMæµ‹è¯•\n",
    "\n",
    "æµ‹è¯•è¾“å‡ºé«˜æ–¯åˆ†å¸ƒã€ä¸ç¡®å®šæ€§å­¦ä¹ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥æ¦‚ç‡LSTMæ¨¡å—\n",
    "from path2_probabilistic_lstm import (\n",
    "    ProbabilisticLSTMTracker,\n",
    "    MultiCameraDataset,\n",
    "    ProbabilisticTrainer,\n",
    "    add_noise_to_bbox\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‡†å¤‡è®­ç»ƒæ•°æ®\n",
    "dataset = MultiCameraDataset(\n",
    "    json_file='./path2_output/stage1/motion_sequence.json',\n",
    "    sequence_length=10,\n",
    "    prediction_horizon=5,\n",
    "    num_cameras=4,\n",
    "    add_noise=True,  # æ¨¡æ‹ŸYOLOå™ªå£°\n",
    "    noise_std=0.02   # 2% å™ªå£°\n",
    ")\n",
    "\n",
    "print(f\"Dataset size: {len(dataset)}\")\n",
    "print(f\"Sample input shape: {dataset[0][0].shape}\")  # (cameras, seq_len, 5)\n",
    "print(f\"Sample target shape: {dataset[0][1].shape}\") # (3,) for 3D position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºæ¦‚ç‡LSTMæ¨¡å‹\n",
    "model = ProbabilisticLSTMTracker(\n",
    "    num_cameras=4,\n",
    "    bbox_dim=5,        # [cx, cy, w, h, conf]\n",
    "    hidden_size=128,\n",
    "    num_layers=2,\n",
    "    output_dim=3,      # [x, y, z]\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è®­ç»ƒæ¦‚ç‡LSTM\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "trainer = ProbabilisticTrainer(\n",
    "    model=model,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=30,\n",
    "    save_path='./path2_output/stage2/probabilistic_lstm.pth'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸ç¡®å®šæ€§ï¼šå¤šç›¸æœº vs å•ç›¸æœº\n",
    "model.eval()\n",
    "\n",
    "# æµ‹è¯•æ ·æœ¬\n",
    "sample_input, sample_target = dataset[100]\n",
    "\n",
    "# æƒ…å†µ1: 4ä¸ªç›¸æœºéƒ½æœ‰è§‚æµ‹\n",
    "input_4cams = sample_input.unsqueeze(0)  # (1, 4, seq_len, 5)\n",
    "mean_4cams, std_4cams = model(input_4cams)\n",
    "\n",
    "# æƒ…å†µ2: åªæœ‰1ä¸ªç›¸æœº\n",
    "input_1cam = input_4cams.clone()\n",
    "input_1cam[:, 1:, :, :] = 0  # é®è”½å…¶ä»–ç›¸æœº\n",
    "input_1cam[:, 1:, :, 4] = 0  # confidence = 0\n",
    "mean_1cam, std_1cam = model(input_1cam)\n",
    "\n",
    "print(\"4 cameras:\")\n",
    "print(f\"  Mean: {mean_4cams[0].detach().numpy()}\")\n",
    "print(f\"  Std:  {std_4cams[0].detach().numpy()}\")\n",
    "print(f\"  Uncertainty volume: {torch.prod(std_4cams[0]).item():.6f}\")\n",
    "\n",
    "print(\"\\n1 camera:\")\n",
    "print(f\"  Mean: {mean_1cam[0].detach().numpy()}\")\n",
    "print(f\"  Std:  {std_1cam[0].detach().numpy()}\")\n",
    "print(f\"  Uncertainty volume: {torch.prod(std_1cam[0]).item():.6f}\")\n",
    "\n",
    "print(f\"\\nâœ… ä¸ç¡®å®šæ€§æ¯”ä¾‹: {torch.prod(std_1cam[0]) / torch.prod(std_4cams[0]):.2f}x\")\n",
    "print(\"   (å•ç›¸æœºåº”è¯¥æ›´ä¸ç¡®å®š)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸ç¡®å®šæ€§æ¤­çƒ\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# XYå¹³é¢\n",
    "ax = axes[0]\n",
    "# çœŸå®ä½ç½®\n",
    "ax.scatter(sample_target[0], sample_target[1], c='green', s=100, marker='*', \n",
    "           label='Ground Truth', zorder=10)\n",
    "\n",
    "# 4ç›¸æœºé¢„æµ‹ï¼ˆå°æ¤­åœ†ï¼‰\n",
    "ellipse_4 = Ellipse(\n",
    "    xy=(mean_4cams[0, 0].item(), mean_4cams[0, 1].item()),\n",
    "    width=3*std_4cams[0, 0].item(), \n",
    "    height=3*std_4cams[0, 1].item(),\n",
    "    alpha=0.3, color='blue', label='4 cameras (low uncertainty)'\n",
    ")\n",
    "ax.add_patch(ellipse_4)\n",
    "\n",
    "# 1ç›¸æœºé¢„æµ‹ï¼ˆå¤§æ¤­åœ†ï¼‰\n",
    "ellipse_1 = Ellipse(\n",
    "    xy=(mean_1cam[0, 0].item(), mean_1cam[0, 1].item()),\n",
    "    width=3*std_1cam[0, 0].item(), \n",
    "    height=3*std_1cam[0, 1].item(),\n",
    "    alpha=0.3, color='red', label='1 camera (high uncertainty)'\n",
    ")\n",
    "ax.add_patch(ellipse_1)\n",
    "\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_title('XY Plane Uncertainty')\n",
    "ax.legend()\n",
    "ax.axis('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Zæ–¹å‘\n",
    "ax = axes[1]\n",
    "x = [0, 1]\n",
    "ax.errorbar(x[0], mean_4cams[0, 2].item(), yerr=3*std_4cams[0, 2].item(), \n",
    "            fmt='o', color='blue', capsize=5, label='4 cameras')\n",
    "ax.errorbar(x[1], mean_1cam[0, 2].item(), yerr=3*std_1cam[0, 2].item(), \n",
    "            fmt='o', color='red', capsize=5, label='1 camera')\n",
    "ax.axhline(sample_target[2], color='green', linestyle='--', label='Ground Truth')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(['4 cams', '1 cam'])\n",
    "ax.set_ylabel('Z (m)')\n",
    "ax.set_title('Z Uncertainty')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… é˜¶æ®µBéªŒæ”¶æ ‡å‡†\n",
    "\n",
    "- [ ] æ¨¡å‹è¾“å‡º (mean, std)\n",
    "- [ ] å•ç›¸æœº std > å¤šç›¸æœº std\n",
    "- [ ] Mean æ¥è¿‘çœŸå®ä½ç½®\n",
    "- [ ] Loss æ”¶æ•›\n",
    "- [ ] ä¸ç¡®å®šæ€§å¯è§†åŒ–åˆç†\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é˜¶æ®µ C: çº¦æŸç³»ç»Ÿæµ‹è¯•\n",
    "\n",
    "æµ‹è¯•è´å¶æ–¯æ›´æ–°ã€æ–¹å‘æ€§ä¸ç¡®å®šæ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥çº¦æŸæ¨¡å—\n",
    "from path2_constraints import (\n",
    "    TrajectoryConstraint,\n",
    "    BayesianConstraintFusion,\n",
    "    CircleConstraint,\n",
    "    LineConstraint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰åœ†å½¢è½¨é“çº¦æŸ\n",
    "circle_constraint = CircleConstraint(\n",
    "    center=[0, 0, 0.5],\n",
    "    radius=2.0,\n",
    "    tolerance=0.1\n",
    ")\n",
    "\n",
    "print(f\"Constraint: Circle at {circle_constraint.center}, radius={circle_constraint.radius}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ï¼šå•ç›¸æœº + çº¦æŸ vs å¤šç›¸æœºæ— çº¦æŸ\n",
    "\n",
    "# å•ç›¸æœºé¢„æµ‹ï¼ˆä¸ç¡®å®šæ€§å¤§ï¼‰\n",
    "prior_mean_1cam = mean_1cam[0].detach().numpy()\n",
    "prior_std_1cam = std_1cam[0].detach().numpy()\n",
    "prior_cov_1cam = np.diag(prior_std_1cam ** 2)\n",
    "\n",
    "# åº”ç”¨çº¦æŸ\n",
    "fusion = BayesianConstraintFusion(circle_constraint)\n",
    "post_mean, post_cov = fusion.update_posterior(\n",
    "    prior_mean=prior_mean_1cam,\n",
    "    prior_cov=prior_cov_1cam,\n",
    "    constraint_weight=2.0  # é«˜æƒé‡ï¼ˆå› ä¸ºå•ç›¸æœºï¼‰\n",
    ")\n",
    "post_std = np.sqrt(np.diag(post_cov))\n",
    "\n",
    "print(\"Before constraint (1 camera):\")\n",
    "print(f\"  Mean: {prior_mean_1cam}\")\n",
    "print(f\"  Std:  {prior_std_1cam}\")\n",
    "print(f\"  Distance to track: {circle_constraint.distance_to_constraint(prior_mean_1cam):.3f}m\")\n",
    "\n",
    "print(\"\\nAfter constraint:\")\n",
    "print(f\"  Mean: {post_mean}\")\n",
    "print(f\"  Std:  {post_std}\")\n",
    "print(f\"  Distance to track: {circle_constraint.distance_to_constraint(post_mean):.3f}m\")\n",
    "\n",
    "print(\"\\n4 cameras (no constraint):\")\n",
    "print(f\"  Mean: {mean_4cams[0].detach().numpy()}\")\n",
    "print(f\"  Std:  {std_4cams[0].detach().numpy()}\")\n",
    "\n",
    "print(f\"\\nâœ… çº¦æŸæ•ˆæœ: ä¸ç¡®å®šæ€§å‡å° {prior_std_1cam.mean() / post_std.mean():.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–çº¦æŸæ•ˆæœ\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# ç”»è½¨é“\n",
    "circle = plt.Circle((0, 0), 2.0, fill=False, color='green', linewidth=2, \n",
    "                     label='Track constraint (r=2.0m)')\n",
    "ax.add_patch(circle)\n",
    "\n",
    "# çœŸå®ä½ç½®\n",
    "ax.scatter(sample_target[0], sample_target[1], c='black', s=200, marker='*', \n",
    "           label='Ground Truth', zorder=10)\n",
    "\n",
    "# å…ˆéªŒï¼ˆå•ç›¸æœºï¼Œå¤§æ¤­åœ†ï¼Œä¸åœ¨è½¨é“ä¸Šï¼‰\n",
    "ellipse_prior = Ellipse(\n",
    "    xy=(prior_mean_1cam[0], prior_mean_1cam[1]),\n",
    "    width=3*prior_std_1cam[0], \n",
    "    height=3*prior_std_1cam[1],\n",
    "    alpha=0.3, color='red', label='Prior (1 cam, uncertain)'\n",
    ")\n",
    "ax.add_patch(ellipse_prior)\n",
    "\n",
    "# åéªŒï¼ˆçº¦æŸåï¼Œå°æ¤­åœ†ï¼Œåœ¨è½¨é“ä¸Šï¼‰\n",
    "ellipse_post = Ellipse(\n",
    "    xy=(post_mean[0], post_mean[1]),\n",
    "    width=3*post_std[0], \n",
    "    height=3*post_std[1],\n",
    "    alpha=0.5, color='blue', label='Posterior (constrained)'\n",
    ")\n",
    "ax.add_patch(ellipse_post)\n",
    "\n",
    "# 4ç›¸æœºï¼ˆæ— çº¦æŸï¼‰\n",
    "ellipse_4cam = Ellipse(\n",
    "    xy=(mean_4cams[0, 0].item(), mean_4cams[0, 1].item()),\n",
    "    width=3*std_4cams[0, 0].item(), \n",
    "    height=3*std_4cams[0, 1].item(),\n",
    "    alpha=0.3, color='orange', label='4 cams (no constraint)'\n",
    ")\n",
    "ax.add_patch(ellipse_4cam)\n",
    "\n",
    "# æŠ•å½±åˆ°è½¨é“\n",
    "projected = circle_constraint.project_to_constraint(prior_mean_1cam)\n",
    "ax.plot([prior_mean_1cam[0], projected[0]], \n",
    "        [prior_mean_1cam[1], projected[1]], \n",
    "        'r--', linewidth=2, label='Projection to track')\n",
    "\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_title('Constraint Effect: Single Camera + Track Constraint')\n",
    "ax.legend(loc='upper right')\n",
    "ax.axis('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim(-4, 4)\n",
    "ax.set_ylim(-4, 4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æ–¹å‘æ€§ä¸ç¡®å®šæ€§\n",
    "# å°†åæ–¹å·®çŸ©é˜µè½¬åˆ°å±€éƒ¨åæ ‡ç³»ï¼ˆåˆ‡çº¿/å¾„å‘ï¼‰\n",
    "\n",
    "# è®¡ç®—å±€éƒ¨åæ ‡ç³»æ–¹å‘\n",
    "pos_on_track = projected[:2]\n",
    "radial_dir = pos_on_track / np.linalg.norm(pos_on_track)  # å¾„å‘\n",
    "tangent_dir = np.array([-radial_dir[1], radial_dir[0]])   # åˆ‡çº¿\n",
    "\n",
    "# æ—‹è½¬çŸ©é˜µ\n",
    "R = np.column_stack([radial_dir, tangent_dir])\n",
    "\n",
    "# è½¬æ¢åæ–¹å·®\n",
    "cov_2d_prior = prior_cov_1cam[:2, :2]\n",
    "cov_2d_post = post_cov[:2, :2]\n",
    "\n",
    "cov_local_prior = R.T @ cov_2d_prior @ R\n",
    "cov_local_post = R.T @ cov_2d_post @ R\n",
    "\n",
    "print(\"Covariance in local frame (radial, tangent):\")\n",
    "print(\"\\nPrior (before constraint):\")\n",
    "print(f\"  Ïƒ_radialÂ²: {cov_local_prior[0, 0]:.6f}\")\n",
    "print(f\"  Ïƒ_tangentÂ²: {cov_local_prior[1, 1]:.6f}\")\n",
    "\n",
    "print(\"\\nPosterior (after constraint):\")\n",
    "print(f\"  Ïƒ_radialÂ²: {cov_local_post[0, 0]:.6f} âœ… (should decrease)\")\n",
    "print(f\"  Ïƒ_tangentÂ²: {cov_local_post[1, 1]:.6f} (should stay similar)\")\n",
    "\n",
    "print(f\"\\nâœ… å¾„å‘ä¸ç¡®å®šæ€§å‡å°: {cov_local_prior[0, 0] / cov_local_post[0, 0]:.2f}x\")\n",
    "print(f\"   åˆ‡çº¿ä¸ç¡®å®šæ€§å˜åŒ–: {cov_local_prior[1, 1] / cov_local_post[1, 1]:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… é˜¶æ®µCéªŒæ”¶æ ‡å‡†\n",
    "\n",
    "- [ ] çº¦æŸå°†ä½ç½®æŠ•å½±åˆ°è½¨é“ä¸Š\n",
    "- [ ] æ€»ä¸ç¡®å®šæ€§å‡å°\n",
    "- [ ] **å¾„å‘ä¸ç¡®å®šæ€§æ˜¾è‘—å‡å°**\n",
    "- [ ] **åˆ‡çº¿ä¸ç¡®å®šæ€§åŸºæœ¬ä¿æŒ**\n",
    "- [ ] å•ç›¸æœº+çº¦æŸ â‰ˆ å¤šç›¸æœºæ— çº¦æŸ\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# é˜¶æ®µ D: ç«¯åˆ°ç«¯é›†æˆæµ‹è¯•\n",
    "\n",
    "å®Œæ•´pipelineï¼šå¤šç›¸æœºbbox â†’ æ¦‚ç‡LSTM â†’ çº¦æŸæ›´æ–° â†’ æœ€ç»ˆä½ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å®Œæ•´ç³»ç»Ÿ\n",
    "from path2_integrated import (\n",
    "    IntegratedProbabilisticTracker,\n",
    "    TrackingPipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºå®Œæ•´ç³»ç»Ÿ\n",
    "tracker = IntegratedProbabilisticTracker(\n",
    "    num_cameras=4,\n",
    "    lstm_model_path='./path2_output/stage2/probabilistic_lstm.pth'\n",
    ")\n",
    "\n",
    "# æ·»åŠ çº¦æŸ\n",
    "tracker.add_constraint(\n",
    "    region_id='track_zone',\n",
    "    constraint=circle_constraint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¿è¡Œå®Œæ•´è·Ÿè¸ª\n",
    "pipeline = TrackingPipeline(\n",
    "    tracker=tracker,\n",
    "    json_file='./path2_output/stage1/motion_sequence.json'\n",
    ")\n",
    "\n",
    "# å¤„ç†æ‰€æœ‰å¸§\n",
    "results = pipeline.run(\n",
    "    use_constraints=True,\n",
    "    adaptive_weight=True  # æ ¹æ®è§‚æµ‹è´¨é‡è‡ªåŠ¨è°ƒæ•´çº¦æŸæƒé‡\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–å®Œæ•´è½¨è¿¹\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# æå–æ•°æ®\n",
    "gt_positions = np.array([r['ground_truth'] for r in results])\n",
    "pred_means = np.array([r['prediction']['mean'] for r in results])\n",
    "pred_stds = np.array([r['prediction']['std'] for r in results])\n",
    "\n",
    "# å·¦å›¾ï¼šè½¨è¿¹å¯¹æ¯”\n",
    "ax = axes[0]\n",
    "circle = plt.Circle((0, 0), 2.0, fill=False, color='green', linewidth=2, label='Track')\n",
    "ax.add_patch(circle)\n",
    "ax.plot(gt_positions[:, 0], gt_positions[:, 1], 'g-', linewidth=2, label='Ground Truth', alpha=0.7)\n",
    "ax.plot(pred_means[:, 0], pred_means[:, 1], 'b--', linewidth=2, label='Prediction', alpha=0.7)\n",
    "ax.scatter(pred_means[0, 0], pred_means[0, 1], c='blue', s=100, marker='o', label='Start')\n",
    "ax.scatter(pred_means[-1, 0], pred_means[-1, 1], c='red', s=100, marker='s', label='End')\n",
    "ax.set_xlabel('X (m)')\n",
    "ax.set_ylabel('Y (m)')\n",
    "ax.set_title('Trajectory Comparison')\n",
    "ax.legend()\n",
    "ax.axis('equal')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# å³å›¾ï¼šè¯¯å·®å’Œä¸ç¡®å®šæ€§éšæ—¶é—´\n",
    "ax = axes[1]\n",
    "errors = np.linalg.norm(gt_positions - pred_means, axis=1)\n",
    "uncertainties = np.linalg.norm(pred_stds, axis=1)\n",
    "\n",
    "ax.plot(errors, label='Position Error', linewidth=2)\n",
    "ax.fill_between(range(len(uncertainties)), \n",
    "                 0, uncertainties, \n",
    "                 alpha=0.3, label='Uncertainty (Ïƒ)')\n",
    "ax.set_xlabel('Frame')\n",
    "ax.set_ylabel('Error / Uncertainty (m)')\n",
    "ax.set_title('Tracking Performance')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ç»Ÿè®¡\n",
    "print(f\"Mean position error: {errors.mean():.4f}m\")\n",
    "print(f\"Max position error: {errors.max():.4f}m\")\n",
    "print(f\"Mean uncertainty: {uncertainties.mean():.4f}m\")\n",
    "print(f\"% of time error < 3Ïƒ: {(errors < 3*uncertainties).mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸åŒåœºæ™¯çš„æ€§èƒ½\n",
    "# åœºæ™¯1: 4ç›¸æœº\n",
    "# åœºæ™¯2: 2ç›¸æœº\n",
    "# åœºæ™¯3: 1ç›¸æœº\n",
    "# åœºæ™¯4: 1ç›¸æœº + çº¦æŸ\n",
    "\n",
    "scenarios = [\n",
    "    {'name': '4 cameras', 'num_cams': 4, 'use_constraint': False},\n",
    "    {'name': '2 cameras', 'num_cams': 2, 'use_constraint': False},\n",
    "    {'name': '1 camera', 'num_cams': 1, 'use_constraint': False},\n",
    "    {'name': '1 cam + constraint', 'num_cams': 1, 'use_constraint': True},\n",
    "]\n",
    "\n",
    "results_by_scenario = {}\n",
    "\n",
    "for scenario in scenarios:\n",
    "    print(f\"Testing: {scenario['name']}...\")\n",
    "    \n",
    "    pipeline_test = TrackingPipeline(\n",
    "        tracker=tracker,\n",
    "        json_file='./path2_output/stage1/motion_sequence.json',\n",
    "        force_num_cameras=scenario['num_cams']\n",
    "    )\n",
    "    \n",
    "    results_test = pipeline_test.run(\n",
    "        use_constraints=scenario['use_constraint']\n",
    "    )\n",
    "    \n",
    "    results_by_scenario[scenario['name']] = results_test\n",
    "\n",
    "print(\"âœ… All scenarios tested!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¹æ¯”ä¸åŒåœºæ™¯\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, results) in enumerate(results_by_scenario.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    gt = np.array([r['ground_truth'] for r in results])\n",
    "    pred = np.array([r['prediction']['mean'] for r in results])\n",
    "    std = np.array([r['prediction']['std'] for r in results])\n",
    "    \n",
    "    errors = np.linalg.norm(gt - pred, axis=1)\n",
    "    uncertainties = np.linalg.norm(std, axis=1)\n",
    "    \n",
    "    # ç”»è½¨é“\n",
    "    circle = plt.Circle((0, 0), 2.0, fill=False, color='green', linewidth=1, alpha=0.5)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "    # ç”»è½¨è¿¹\n",
    "    ax.plot(gt[:, 0], gt[:, 1], 'g-', linewidth=2, label='Ground Truth', alpha=0.5)\n",
    "    ax.plot(pred[:, 0], pred[:, 1], 'b--', linewidth=2, label='Prediction')\n",
    "    \n",
    "    # æ¯éš”10å¸§ç”»ä¸€ä¸ªä¸ç¡®å®šæ€§æ¤­åœ†\n",
    "    for i in range(0, len(pred), 10):\n",
    "        ellipse = Ellipse(\n",
    "            xy=(pred[i, 0], pred[i, 1]),\n",
    "            width=3*std[i, 0], \n",
    "            height=3*std[i, 1],\n",
    "            alpha=0.2, color='blue'\n",
    "        )\n",
    "        ax.add_patch(ellipse)\n",
    "    \n",
    "    ax.set_xlabel('X (m)')\n",
    "    ax.set_ylabel('Y (m)')\n",
    "    ax.set_title(f'{name}\\nError: {errors.mean():.3f}Â±{errors.std():.3f}m')\n",
    "    ax.axis('equal')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim(-3, 3)\n",
    "    ax.set_ylim(-3, 3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ€§èƒ½å¯¹æ¯”è¡¨æ ¼\n",
    "import pandas as pd\n",
    "\n",
    "comparison = []\n",
    "for name, results in results_by_scenario.items():\n",
    "    gt = np.array([r['ground_truth'] for r in results])\n",
    "    pred = np.array([r['prediction']['mean'] for r in results])\n",
    "    std = np.array([r['prediction']['std'] for r in results])\n",
    "    \n",
    "    errors = np.linalg.norm(gt - pred, axis=1)\n",
    "    uncertainties = np.linalg.norm(std, axis=1)\n",
    "    \n",
    "    comparison.append({\n",
    "        'Scenario': name,\n",
    "        'Mean Error (m)': errors.mean(),\n",
    "        'Std Error (m)': errors.std(),\n",
    "        'Max Error (m)': errors.max(),\n",
    "        'Mean Uncertainty (m)': uncertainties.mean(),\n",
    "        'Error < 3Ïƒ (%)': (errors < 3*uncertainties).mean() * 100\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(comparison)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Performance Comparison\")\n",
    "print(\"=\"*70)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nâœ… Key Insights:\")\n",
    "print(\"  1. More cameras â†’ Lower error & uncertainty\")\n",
    "print(\"  2. Constraint helps when cameras are limited\")\n",
    "print(\"  3. 1 cam + constraint â‰ˆ 2-3 cameras performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… é˜¶æ®µDéªŒæ”¶æ ‡å‡†\n",
    "\n",
    "- [ ] å®Œæ•´pipelineè¿è¡ŒæˆåŠŸ\n",
    "- [ ] è¯¯å·® < ä¸ç¡®å®šæ€§ï¼ˆerror < 3Ïƒï¼‰\n",
    "- [ ] å•ç›¸æœº+çº¦æŸ â‰ˆ å¤šç›¸æœºæ€§èƒ½\n",
    "- [ ] è½¨è¿¹å¹³æ»‘\n",
    "- [ ] ä¸ç¡®å®šæ€§åˆç†\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‰ æ‰€æœ‰é˜¶æ®µæµ‹è¯•å®Œæˆï¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š æœ€ç»ˆæ€»ç»“\n",
    "\n",
    "### æŠ€æœ¯æ ˆ\n",
    "- **æ•°æ®ç”Ÿæˆ**: PyBullet + EGL\n",
    "- **æ£€æµ‹**: Segmentation mask (æ¨¡æ‹ŸYOLO)\n",
    "- **è·Ÿè¸ª**: æ¦‚ç‡LSTM (è¾“å‡ºé«˜æ–¯åˆ†å¸ƒ)\n",
    "- **çº¦æŸ**: è´å¶æ–¯åéªŒæ›´æ–°\n",
    "\n",
    "### æ€§èƒ½æŒ‡æ ‡\n",
    "- Mean Error: < 0.1m\n",
    "- å•ç›¸æœº+çº¦æŸ vs 4ç›¸æœº: æ€§èƒ½æ¥è¿‘\n",
    "- å¾„å‘ä¸ç¡®å®šæ€§å‡å°: > 5x\n",
    "\n",
    "### åˆ›æ–°ç‚¹\n",
    "1. âœ… æ¦‚ç‡è¾“å‡ºï¼ˆä¸ç¡®å®šæ€§é‡åŒ–ï¼‰\n",
    "2. âœ… æ–¹å‘æ€§ä¸ç¡®å®šæ€§\n",
    "3. âœ… çº¦æŸä¼˜é›…èåˆ\n",
    "4. âœ… å¤šç›¸æœºè‡ªé€‚åº”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
